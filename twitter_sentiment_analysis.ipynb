{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "\n",
        "nltk.download([\"names\",\"stopwords\",\"state_union\",\"twitter_samples\",\"movie_reviews\",\"averaged_perceptron_tagger\",\"vader_lexicon\",\"punkt\"])\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VppzHlbz5kS-",
        "outputId": "0dc3fa86-9c49-429f-ef1d-c4a80485477c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]   Package state_union is already up-to-date!\n",
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "yCQC1tDk5KRS",
        "outputId": "195d4548-a649-49f8-fb71-4ad7758d1934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n",
            "Neutral\n",
            "Positive\n",
            "Positive\n",
            "Positive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor i in dictionary_freq.values():\\n  fd = nltk.FreqDist(i)\\n  print(fd.most_common(3))\\n  #fd.tabulate(3)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "import tweepy\n",
        "\n",
        "consumer_key = \"w0M0ZPzdxWcbRqe0xl4uGkPil\"\n",
        "consumer_secret = \"OZnzyhAv6FbR8fnJgYpKtUirFiYNKYoNQR4EQ1ScqkeNmN5Nxa\"\n",
        "access_token = \"1265819169934606341-GB6AFNwIp5iPCH93NweJhSI9lA2qwm\"\n",
        "access_token_secret = \"mdk1c2RxyIZxbH4u9uS8qpnf7GwmmkmbZOEotveUTjgaS\"\n",
        "\n",
        "# Creating the authentication object\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "# Setting your access token and secret\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "# Creating the API object while passing in auth information\n",
        "api = tweepy.API(auth) \n",
        "tweets = api.user_timeline(user_id = \"44196397\", count = 5, include_rts = False)\n",
        "#public_tweets = api.get_retweets(status)\n",
        "# foreach through all tweets pulled\n",
        "dictionary_letters= {}\n",
        "dictionary_freq = {}\n",
        "dictionary_score = {}\n",
        "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "for tweet in tweets:\n",
        "   # printing the text stored inside the tweet object\n",
        "   #words = [w for w in tweet.text if w.isalpha()]\n",
        "   #words = [w for w in words if w.lower() not in stopwords]\n",
        "   freq = nltk.word_tokenize(tweet.text)\n",
        "   #print(freq)\n",
        "   fd = nltk.FreqDist(freq)\n",
        "   score = sia.polarity_scores(tweet.text)\n",
        "   #print(tweet.text)\n",
        "   #dictionary_letters[tweet.id] = words\n",
        "   dictionary_freq[tweet.id] = fd\n",
        "   dictionary_score[tweet.id] = score[\"compound\"]\n",
        "\n",
        "dictionary_tweet_sentiment = {}\n",
        "\n",
        "for i in dictionary_score:\n",
        "  if dictionary_score[i] > 0:\n",
        "    dictionary_tweet_sentiment[i] = \"Positive\"\n",
        "  elif dictionary_score[i] == 0:\n",
        "    dictionary_tweet_sentiment[i] = \"Neutral\"\n",
        "  else:\n",
        "    dictionary_tweet_sentiment[i] = \"Negative\"\n",
        "\n",
        "postive = 0\n",
        "negative = 0\n",
        "neutral = 0\n",
        "sum = 0\n",
        "for i in dictionary_tweet_sentiment.values():\n",
        "  print(i)\n",
        "\n",
        "\n",
        "'''\n",
        "for i in dictionary_freq.values():\n",
        "  fd = nltk.FreqDist(i)\n",
        "  print(fd.most_common(3))\n",
        "  #fd.tabulate(3)\n",
        "'''\n"
      ]
    }
  ]
}